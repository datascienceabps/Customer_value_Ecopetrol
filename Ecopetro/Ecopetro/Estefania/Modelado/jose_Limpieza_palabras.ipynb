{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"jose_Limpieza_palabras.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1HAKkvFsn4KBomo9W8fAfBRbB84WIarNF","authorship_tag":"ABX9TyNk+oA10EWsBspV9YoDxYPY"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"hAMLwDBs1_zy"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UipwJG18120s"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fjBwsUj7tkQ0","executionInfo":{"status":"ok","timestamp":1623345376801,"user_tz":300,"elapsed":4013,"user":{"displayName":"José Ignacio Barraquer","photoUrl":"","userId":"08708218907280127573"}},"outputId":"3b1e6ebe-799b-4aa6-ceac-c277f7eecaf5"},"source":["package = ['boto3','es_lemmatizer','pyodbc','prince']\n","f= open(\"paquetes.txt\",\"w+\")\n","\n","def install_txt(package):\n","  f= open(\"paquetes.txt\",\"w+\")\n","  for i in package:\n","    print(i)\n","    \n","\n","    try:\n","        __import__(i)\n","        print('ya instalado {}'.format(i))\n","    except ImportError:\n","        # main(['install', package]) \n","        f.write(\"{} \\r\\n\".format(i))\n","        print('No instalado {}'.format(i))\n","\n","\n","install_txt(package) "],"execution_count":null,"outputs":[{"output_type":"stream","text":["boto3\n","ya instalado boto3\n","es_lemmatizer\n","ya instalado es_lemmatizer\n","pyodbc\n","ya instalado pyodbc\n","prince\n","ya instalado prince\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"9519fOehuwM7"},"source":["!pip install -r paquetes.txt"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"heading_collapsed":true,"id":"PygjTyuks2H9"},"source":["#**librerias**"]},{"cell_type":"code","metadata":{"hidden":true,"id":"dzBNKajQs2H_","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1623345380832,"user_tz":300,"elapsed":1001,"user":{"displayName":"José Ignacio Barraquer","photoUrl":"","userId":"08708218907280127573"}},"outputId":"ce8ace2e-db25-446e-886a-28e9e673c174"},"source":["#Librerias\n","import re\n","import numpy as np\n","import pandas as pd\n","import pandas_profiling\n","from pathlib import Path\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","from PIL import Image\n","from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n","import nltk\n","nltk.download('stopwords')\n","import matplotlib.pyplot as plt\n","from nltk.tokenize import word_tokenize, sent_tokenize\n","from nltk.corpus import stopwords\n","import unicodedata\n","from es_lemmatizer import lemmatize\n","import spacy\n","import re\n","import pyodbc\n","import prince\n","from collections import Counter "],"execution_count":null,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/requests/__init__.py:91: RequestsDependencyWarning: urllib3 (1.26.5) or chardet (3.0.4) doesn't match a supported version!\n","  RequestsDependencyWarning)\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"heading_collapsed":true,"id":"0d2DhJNKs2IB"},"source":["#**Rutas**"]},{"cell_type":"code","metadata":{"id":"m6DT7A9otIgj"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"hidden":true,"id":"e8cgIJJAs2IB"},"source":["observador_personal  = '/content/drive/MyDrive/Ecopetro/Estefania/Observaciones_LimpiezaInicial_Personal.csv'\n","observador_operacion_finaciera='/content/drive/MyDrive/Ecopetro/Estefania/Observaciones_LimpiezaInicial_OpeFinanciera.csv'\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"heading_collapsed":true,"id":"bU1MeK8Ms2IC"},"source":["#**Funciones**"]},{"cell_type":"code","metadata":{"hidden":true,"id":"Z9zc9Wsfs2IC"},"source":["#esta funcion quita stop words de cada una de las filas\n","def text_rows(texto, StopWords):\n","    texto = texto.split()\n","    resultwords  = [word for word in texto if word not in StopWords]\n","    texto = ' '.join(resultwords)\n","    return texto\n","\n","\n","def text (column, dic):\n","    column = column.astype(str)\n","    texto_base = \" \".join(motivo for motivo in column)\n","    text = (unicodedata.normalize('NFKD', texto_base).encode('ascii', 'ignore').decode('utf-8', 'ignore').lower())\n","    text = re.sub(r\"\\bmedicas\\b\",\"medica\",text)\n","    for i, j in dic.items():\n","        text = text.replace(i, j)\n","        \n","    return text\n","    \n","def listas (column, dic):\n","    Lista = []\n","    column = columna.astype(str)\n","    for motivo in column:\n","        inicial_answer = str(motivo)\n","        for i, j in dic.items():\n","            ini_answer = inicial_answer.replace(i, j)\n","        answer = (unicodedata.normalize('NFKD', ini_answer).encode('ascii', 'ignore').decode('utf-8', 'ignore').lower())\n","        answer = re.sub(r\"\\bmedicas\\b\",\"medica\",answer)\n","        answer = re.sub(r\"\\bmedicamentos\\b\",\"medicamento\",answer)\n","        answer = re.sub(r'[^\\w\\s]','', answer).split()\n","        words = [word for word in answer if word not in stop_words]\n","        Lista.append(words)\n","    return Lista\n","    \n","#crea nube de palabras\n","def wordcloud(text, nombre, stopWords):\n","    # wordcloud = WordCloud(stopwords=stop_words+stopWords, background_color=\"white\", width=1600, height=800,min_word_length =3 ).generate(text)\n","    wordcloud = WordCloud(stopwords=stop_words+stopWords, background_color=\"white\", width=1600, height=800).generate(text)\n","    plt.figure( figsize=(15,10) )\n","    plt.imshow(wordcloud, interpolation='bilinear')\n","    plt.axis(\"off\")\n","    plt.show()\n","    plt.savefig(\"word_cloud_\"+str(nombre)+\".png\") #dpi = 300)    \n","\n","#crea n-gramas   \n","def ngrams(text, n, top,stopWords):\n","    #wnl = nltk.stem.WordNetLemmatizer()\n","    texto = re.sub(r'[^\\w\\s]','', text).split()\n","    stopwords = stop_words + stopWords\n","    words = [word for word in texto if word not in stopwords]\n","    \n","    n_grams_series = ((pd.Series(nltk.ngrams(words,n)).value_counts())[:top])\n","    plot = n_grams_series.sort_values().plot.barh(color =\"tomato\", width = 0.6, figsize = (20,18), edgecolor='grey')   #color=(0.2, 0.4, 0.6, 0.6)\n","    plot.set_xlabel('Frecuencia',  fontname=\"Calibri\", fontsize=35)\n","    plot.set_title('TOP ' + str(top) +' de '+str(n)+'-GRAMAS QUE APARECEN CON MAYOR FRECUENCIA', fontname=\"Calibri\", fontsize=40)\n","    plot.title.set_position([.5, 1.05])\n","    for tick in  plot.get_xticklabels():\n","        tick.set_fontname(\"Calibri\")\n","        tick.set_fontsize(35)\n","    for tick in  plot.get_yticklabels():\n","        tick.set_fontname(\"Calibri\")\n","        tick.set_fontsize(35)\n","    #plt.savefig(\"graph.png\") #dpi = 300)\n","    plt.figure( figsize=(15,10) )\n","    #plt.show()\n","    return n_grams_series\n","    #if n == 1 :\n","    #    return n_grams_series.to_frame().reset_index().rename(columns = {'index':'palabras', 0:'Conteo'})\n","    #elif n == 2:\n","    #    return n_grams_series.to_frame().reset_index().rename(columns = {'index':'Bigramas', 0:'Conteo'})\n","    #elif n > 2:\n","    #    return n_grams_series.to_frame().reset_index().rename(columns = {'index':'gramas', 0:'Conteo'})\n","\n","def wordcloud_jose(x):\n","  lista_mensajeuser=[]\n","  \n","  long_string=''.join(x)\n","  sal = pd.Series(long_string.split(' ')).value_counts()\n","  saldic = sal.to_dict()\n","  #Creacion lista stop words\n","  wordcloud = WordCloud(background_color=\"white\",min_font_size=5, max_font_size=150, max_words=600, contour_width=50,\n","                        contour_color='steelblue', margin=15, stopwords=StopWords_total,width=1600, height=800)\n","  \n","  wordcloud2 = WordCloud(background_color=\"white\",min_font_size=5, max_font_size=150, max_words=20, contour_width=50,\n","                      contour_color='steelblue', margin=15, stopwords=StopWords_total,width=1600, height=800)\n","  #Crear el word cloud\n","  #wordcloud.generate(long_string)\n","  wordcloud.generate_from_frequencies(saldic)\n","  wordcloud2.generate_from_frequencies(saldic)\n","  # wordcloud.generate(saldic)\n","  #Visualizar el word cloud\n","  plt.figure( figsize=(15,10) )\n","  \n","  plt.imshow(wordcloud, interpolation='bilinear')\n","  plt.axis(\"off\")\n","  plt.show()\n","  \n","  plt.figure( figsize=(15,10) )\n","  plt.imshow(wordcloud2, interpolation='bilinear')\n","  plt.axis(\"off\")\n","  plt.show()\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"14bgeoyws2ID"},"source":["#**STOPWORDS**"]},{"cell_type":"code","metadata":{"id":"IlA778Pls2ID"},"source":["#nombres\n","filename = \"/content/drive/MyDrive/Ecopetro/Estefania/nombres_apellidos.txt\"\n","with open(filename) as f:\n","    nombres = f.readlines()\n","# you may also want to remove whitespace characters like `\\n` at the end of each line\n","nombres = [x.strip() for x in nombres] \n","\n","#Stopwords en general\n","\n","GENERAL_STOPWORDS = []\n","\n","\n","#lista base\n","stop_words = nltk.corpus.stopwords.words('spanish') + GENERAL_STOPWORDS + nombres\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"heading_collapsed":true,"id":"dfxkyV9Os2IE"},"source":["# **Extraccion observaciones**"]},{"cell_type":"code","metadata":{"hidden":true,"scrolled":true,"id":"rDcTHiLys2IE","colab":{"base_uri":"https://localhost:8080/","height":496},"executionInfo":{"status":"ok","timestamp":1623345381182,"user_tz":300,"elapsed":178,"user":{"displayName":"José Ignacio Barraquer","photoUrl":"","userId":"08708218907280127573"}},"outputId":"e5654f0a-66b8-4eea-d535-0645f12eeee2"},"source":["beneficios = pd.read_csv(observador_personal)\n","beneficios.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>fgs_IdGestion</th>\n","      <th>fgs_Nivel3</th>\n","      <th>ObservacionCreacion_limpieza1</th>\n","      <th>ObservacionSolucion_limpieza1</th>\n","      <th># palabras_ObsCreacion_sinLim</th>\n","      <th># palabras_ObsSolucion_sinLim</th>\n","      <th># palabras_ObsCreacion_limpieza1</th>\n","      <th># palabras_ObsSolucion_limpieza1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>13908445</td>\n","      <td>Legal / Reconocimiento Pensionados (Incluye Su...</td>\n","      <td>se recibe documentacion del senor joaquin erne...</td>\n","      <td>se informa que su caso no puede ser tramitado...</td>\n","      <td>18</td>\n","      <td>228</td>\n","      <td>18</td>\n","      <td>238</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>13908527</td>\n","      <td>Legal / Reconocimiento Pensionados (Incluye Su...</td>\n","      <td>solicito el ajuste de semestre y se encuentra ...</td>\n","      <td>se realizo el ajuste de semestre y se encuentr...</td>\n","      <td>12</td>\n","      <td>13</td>\n","      <td>12</td>\n","      <td>13</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>13908581</td>\n","      <td>Legal / Reconocimiento Pensionados (Incluye Su...</td>\n","      <td>se recibe solicitud de legalizacion semestre s...</td>\n","      <td>se informa a la peticionaria que este caso fue...</td>\n","      <td>20</td>\n","      <td>17</td>\n","      <td>18</td>\n","      <td>16</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>13908589</td>\n","      <td>Legal / Reconocimiento Pensionados (Incluye Su...</td>\n","      <td>solicitud del usuario ayer envie este mismo do...</td>\n","      <td>gestion realizada dando respuesta a la consult...</td>\n","      <td>22</td>\n","      <td>250</td>\n","      <td>25</td>\n","      <td>247</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>13908640</td>\n","      <td>Legal / Reconocimiento Pensionados (Incluye Su...</td>\n","      <td>se recibe solicitud de legalizacion de luisa f...</td>\n","      <td>se informa que debe anexar certificacion de un...</td>\n","      <td>10</td>\n","      <td>27</td>\n","      <td>10</td>\n","      <td>27</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   fgs_IdGestion  ... # palabras_ObsSolucion_limpieza1\n","0       13908445  ...                              238\n","1       13908527  ...                               13\n","2       13908581  ...                               16\n","3       13908589  ...                              247\n","4       13908640  ...                               27\n","\n","[5 rows x 8 columns]"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"markdown","metadata":{"heading_collapsed":true,"hidden":true,"id":"yzY6YoaOs2IE"},"source":["## **GRUPOS**"]},{"cell_type":"code","metadata":{"hidden":true,"id":"39nPvgLhs2IF"},"source":["GRUPOS = ['1. Legalización','1. Legalización','2. Solicitud de educación inclusiva'\n","          ,'3. Anticipo','3. Anticipo','3. Anticipo','3. Anticipo'\n","          ,'4. Consulta','4. Consulta','4. Consulta','4. Consulta','4. Consulta'\n","          ,'4. Consulta','4. Consulta','5. Soporte Plataforma'\n","          ,'6. Reintegro','6. Reintegro','7. Inscripción','7. Inscripción','7. Inscripción']\n","\n","NIVELES = ['Legal / Reconocimiento Pensionados (Incluye Sustitutos)'\n","           ,'Legal / Reconocimiento Trabajadores (Incluye Bachiller ECP)'\n","           ,'Solicitud de educación inclusiva'\n","           ,'Anticipo Pensionados Educación Inclusiva','Anticipo Trabajadores Educación Inclusiva'\n","            ,'Anticipo Pensionados (Incluye Sustitutos)','Anticipo Trabajadores (Incluye BXC)'\n","            ,'Consulta Bachiller Ecopetrol (Incapacidad médica y/o Fuerza Mayor)'\n","            ,'Consulta de información relacionadas con reembolsos'\n","            ,'Consulta especialista beneficios atención PQRS'\n","            ,'Consulta sobre liquidación/pago préstamo para educación'\n","            ,'Consulta Titulares Beneficio Eductivo - Desvinculados'\n","            ,'Consultas Titulares Beneficio Educativo (No Incluye Bachiller ECP)'\n","            ,'Solicitud / Consulta / revisión pagos colegios propiedad de Ecopetrol S.A.'\n","            ,'Soporte Plataforma para Instituciones Educativas vía TIB'\n","            ,'Reintegro de dinero Pensionados Educación (Incluye sustitutos y Auto)'\n","            ,'Reintegro de dinero trabajadores Educación (Incluye Bachiller ECP)'\n","            ,'Inscripción casos especiales comité de educación convencional activos'\n","            ,'Inscripción casos especiales comité educación convencional pensionados'\n","            ,'Inscripción solicitud becas Comité de Educación Convencional Activos']\n","\n","dic_grupos = dict(zip(NIVELES,GRUPOS))\n","\n","beneficios['GRUPOS'] = beneficios['fgs_Nivel3']\n","beneficios['GRUPOS'].replace(dic_grupos, inplace=True)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"heading_collapsed":true,"hidden":true,"id":"_v_mKO3Vs2IF"},"source":["## **PALABRAS DEL DOCUMENTOS DE CARACTERIZACION**"]},{"cell_type":"code","metadata":{"hidden":true,"id":"IrlinTHLs2IG"},"source":["caracterizacion_palabras = pd.read_excel('/content/drive/MyDrive/Ecopetro/Estefania/Caracterizacion_inicial_palabras.xlsx', sheet_name = 'Beneficios-obsCreacion')\n","caracterizacion_palabras = caracterizacion_palabras.replace(regex= [r\"\\(\", r\"\\),\", r\"\\[\", r\"\\]\", r\"\\'\", r\",\"] , value=\"\")\n","caracterizacion_palabras['Palabras '] = caracterizacion_palabras['Palabras '].str.strip()\n","caracterizacion_palabras.rename(columns = {'Palabras ':'StopWords'}, inplace = True)\n","df_total = beneficios\n","caracterizacion_palabras['fgs_Nivel3'] = list(df_total['fgs_Nivel3'].unique())"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HJzijYn2s2IG"},"source":["# **NUBES DE PALABRAS Y NGRAMAS POR GRUPO**"]},{"cell_type":"code","metadata":{"id":"RV_druNbs2IG"},"source":["#**stopwords**"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zlyS-2l9s2IG"},"source":["stop_words_grupo = { '1. Legalización': []\n","                    , '2. Solicitud de educación inclusiva':[]\n","                    , '3. Anticipo': []\n","                    , '4. Consulta': []\n","                    , '5. Soporte Plataforma': []\n","                    , '6. Reintegro': []\n","                    , '7. Inscripción': []}"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3dAE0ipSs2IH"},"source":["#palabras obtenidas de la tabla de caracterizacion\n","StopWordGroups = str(caracterizacion_palabras['StopWords'].unique())\n","StopWordGroups = StopWordGroups.replace(\"[\",\"\").replace(\"'\",\"\").replace(\"\\n\",\"\").replace(\"]\",\"\").replace(\")\",\"\")#.replace(r\"\\)\",\"\").replace(r\"\\[\",\"\").replace(r\"\\]\",\"\").replace(r\"'\\n '\",\"\")\n","SW_grupos = StopWordGroups.split(' ')\n","\n","dic = {}"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2PXKRQPcs2IH"},"source":["#SW_grupos"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HUkUdilhs2IH"},"source":["#**Remoción de stopwords**"]},{"cell_type":"code","metadata":{"scrolled":false,"id":"dS6WIfMRs2IH","colab":{"base_uri":"https://localhost:8080/","height":204},"executionInfo":{"status":"ok","timestamp":1623345443160,"user_tz":300,"elapsed":61857,"user":{"displayName":"José Ignacio Barraquer","photoUrl":"","userId":"08708218907280127573"}},"outputId":"20e61d58-3048-4d0f-8edc-6aea66975d18"},"source":["# df_total = beneficios# se crea aqui ? jose\n","#se crea columna con observaciones que se van a reducir\n","df_total['ObservacionCreacion_limpieza2'] = df_total['ObservacionCreacion_limpieza1']\n","\n","for i in list(df_total['GRUPOS'].unique()):\n","        StopWords_total = stop_words_grupo[i] + stop_words\n","        df_total.loc[df_total['GRUPOS'] == i, 'ObservacionCreacion_limpieza2'] = df_total[df_total['GRUPOS'] == i].ObservacionCreacion_limpieza2.apply(lambda x : text_rows(x,StopWords_total))\n","df_total[['ObservacionCreacion_limpieza1', 'ObservacionCreacion_limpieza2']].head(5)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>ObservacionCreacion_limpieza1</th>\n","      <th>ObservacionCreacion_limpieza2</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>se recibe documentacion del senor joaquin erne...</td>\n","      <td>recibe documentacion senor legalizacion plan e...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>solicito el ajuste de semestre y se encuentra ...</td>\n","      <td>solicito ajuste semestre encuentra proceso val...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>se recibe solicitud de legalizacion semestre s...</td>\n","      <td>recibe solicitud legalizacion semestre evidenc...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>solicitud del usuario ayer envie este mismo do...</td>\n","      <td>solicitud usuario ayer envie mismo documento o...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>se recibe solicitud de legalizacion de luisa f...</td>\n","      <td>recibe solicitud legalizacion</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                       ObservacionCreacion_limpieza1                      ObservacionCreacion_limpieza2\n","0  se recibe documentacion del senor joaquin erne...  recibe documentacion senor legalizacion plan e...\n","1  solicito el ajuste de semestre y se encuentra ...  solicito ajuste semestre encuentra proceso val...\n","2  se recibe solicitud de legalizacion semestre s...  recibe solicitud legalizacion semestre evidenc...\n","3  solicitud del usuario ayer envie este mismo do...  solicitud usuario ayer envie mismo documento o...\n","4  se recibe solicitud de legalizacion de luisa f...                      recibe solicitud legalizacion"]},"metadata":{"tags":[]},"execution_count":14}]},{"cell_type":"markdown","metadata":{"id":"muakzQyYs2II"},"source":["#**Nubes de palabras y n-gramas**"]},{"cell_type":"code","metadata":{"id":"poqMAeZd6nke"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qD3uSyOm6obg"},"source":["## PARA LOS TEXTOS CRUDOS"]},{"cell_type":"code","metadata":{"id":"EhEdvbBGs2II"},"source":["for i in list(df_total['GRUPOS'].unique()):\n","    StopWords_total = stop_words_grupo[i] + stop_words #+ SW_grupos\n","    df_texto =  df_total[df_total['GRUPOS'] == i]\n","    #palabras = caracterizacion_palabras[caracterizacion_palabras['fgs_Nivel3'] == i].reset_index()\n","    texto = text(df_texto['ObservacionCreacion_limpieza1'], dic)\n","    print(i.upper(),' Total Registros: ',df_texto.shape[0])\n","    print(\"  \")\n","    print(\"Observaciones base\")\n","    print(df_texto['ObservacionCreacion_limpieza1'].value_counts()[:5])\n","    print(\"  \")\n","    print(\"Observaciones reducidas\")\n","    print(df_texto['ObservacionCreacion_limpieza1'].value_counts()[:5])\n","    #palabras['StopWords'].str.split(' ')[0]\n","    # wordcloud(texto, i , StopWords_total)\n","    wordcloud_jose(texto)\n","    for i in range(2,6):\n","        print(ngrams(texto, i, 10, StopWords_total))\n","    print('-----------------------------------------------------------------------------------------------')\n","    "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OcsqmbIp67TP"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xWWS4Ys_67re"},"source":["## PARA LOS TEXTOS LIMPIADOS"]},{"cell_type":"code","metadata":{"id":"lFKevnhY67rf"},"source":["for i in list(df_total['GRUPOS'].unique()):\n","    StopWords_total = stop_words_grupo[i] + stop_words #+ SW_grupos\n","    df_texto =  df_total[df_total['GRUPOS'] == i]\n","    #palabras = caracterizacion_palabras[caracterizacion_palabras['fgs_Nivel3'] == i].reset_index()\n","    texto = text(df_texto['ObservacionCreacion_limpieza2'], dic)\n","    print(i.upper(),' Total Registros: ',df_texto.shape[0])\n","    print(\"  \")\n","    print(\"Observaciones base\")\n","    print(df_texto['ObservacionCreacion_limpieza2'].value_counts()[:5])\n","    print(\"  \")\n","    print(\"Observaciones reducidas\")\n","    print(df_texto['ObservacionCreacion_limpieza2'].value_counts()[:5])\n","    #palabras['StopWords'].str.split(' ')[0]\n","    # wordcloud(texto, i , StopWords_total)\n","    wordcloud_jose(texto)\n","    for i in range(2,6):\n","        print(ngrams(texto, i, 10, StopWords_total))\n","    print('-----------------------------------------------------------------------------------------------')\n","    "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XNLNdo9as2II"},"source":["#**Adición de stopwords**"]},{"cell_type":"code","metadata":{"id":"_l4wwyOhs2II"},"source":["stop_words_grupo['1. Legalización'] = ['buenas','legalizacion','plan','educacional', 'solicita, informacion', 'solicitud', 'reconocimiento', 'caso', 'escalo']\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CTRTc3tIs2IJ"},"source":[""],"execution_count":null,"outputs":[]}]}